name: Update data and compute AIBPS

on:
  schedule:
    - cron: "0 */6 * * *"   # every 6 hours (UTC)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    concurrency:
      group: aibps-update
      cancel-in-progress: false

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0
          persist-credentials: true

      - name: Show branch and last commit
        run: |
          echo "Branch: $(git rev-parse --abbrev-ref HEAD)"
          echo "Commit: $(git rev-parse HEAD)"
          git log -1 --stat

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ----- MARKET (SAFE) -----
      - name: Fetch market proxies (SAFE)
        run: |
          python src/aibps/fetch_market_safe.py

      - name: Sanity print market tail
        run: |
          echo "---- TAIL: data/processed/market_processed.csv ----"
          if [ -f data/processed/market_processed.csv ]; then
            tail -n 10 data/processed/market_processed.csv
          else
            echo "market_processed.csv missing"
          fi

      # ----- CREDIT (FRED) -----
      - name: Fetch credit (FRED)
        env:
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
        run: |
          python src/aibps/fetch_credit.py

      - name: Sanity print credit tail
        run: |
          echo "---- TAIL: data/processed/credit_fred_processed.csv ----"
          if [ -f data/processed/credit_fred_processed.csv ]; then
            tail -n 10 data/processed/credit_fred_processed.csv
          else
            echo "credit_fred_processed.csv missing"
          fi

      # ----- CAPEX (manual CSV) -----
      - name: Fetch Capex (manual CSV)
        run: |
          python src/aibps/fetch_capex.py

      - name: Sanity print capex tail
        run: |
          echo "---- TAIL: data/processed/capex_processed.csv ----"
          if [ -f data/processed/capex_processed.csv ]; then
            tail -n 10 data/processed/capex_processed.csv
          else
            echo "capex_processed.csv missing"
          fi
      # ----- MACRO CAPEX (FRED) -----
      - name: Fetch macro Capex (FRED PNRESCAPQUSQ)
        env:
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
        run: |
          python src/aibps/fetch_macro_capex.py

      - name: Sanity print macro capex tail
        run: |
          echo "---- TAIL: data/processed/macro_capex_processed.csv ----"
          if [ -f data/processed/macro_capex_processed.csv ]; then
            tail -n 10 data/processed/macro_capex_processed.csv
          else
            echo "macro_capex_processed.csv missing"
          fi
      
      # ----- INFRA (manual CSV) -----
      - name: Fetch Infra (manual CSV)
        run: |
          python src/aibps/fetch_infra.py

      - name: Sanity print infra tail
        run: |
          echo "---- TAIL: data/processed/infra_processed.csv ----"
          if [ -f data/processed/infra_processed.csv ]; then
            tail -n 10 data/processed/infra_processed.csv
          else
            echo "infra_processed.csv missing"
          fi


      # ----- COMPUTE -----
      - name: Compute AIBPS
        run: |
          python src/aibps/compute.py

      - name: Sanity print composite tail
        run: |
          echo "---- TAIL: data/processed/aibps_monthly.csv ----"
          if [ -f data/processed/aibps_monthly.csv ]; then
            tail -n 12 data/processed/aibps_monthly.csv
          else
            echo "aibps_monthly.csv missing"
          fi

      # ----- BUILD METADATA -----
      - name: Write build metadata
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_RUN_NUMBER: ${{ github.run_number }}
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF: ${{ github.ref }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          python - << 'PY'
          import os, json, time
          repo = os.environ.get('GITHUB_REPOSITORY','')
          run_id = os.environ.get('GITHUB_RUN_ID','')
          run_url = f"https://github.com/{repo}/actions/runs/{run_id}" if repo and run_id else None
          ref = os.environ.get('GITHUB_REF','')
          short_ref = ref.split('/')[-1] if ref else ''
          meta = {
            "updated_at_utc": time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            "github_run_id": run_id,
            "github_run_number": os.environ.get('GITHUB_RUN_NUMBER'),
            "github_sha": os.environ.get('GITHUB_SHA'),
            "github_ref": short_ref,
            "github_run_url": run_url,
            "github_repository": repo,
          }
          os.makedirs('data/processed', exist_ok=True)
          with open('data/processed/metadata.json','w') as f:
              json.dump(meta, f, indent=2)
          print(json.dumps(meta, indent=2))
          PY

      # ----- COMMIT & PUSH -----
      - name: Commit processed files
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/raw/*.csv data/processed/*.csv data/processed/metadata.json || true

          if git diff --cached --quiet; then
            echo "No data changes to commit."
            exit 0
          fi

          git fetch origin main
          git pull --rebase origin main || true

          git commit -m "Auto-update data ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))" || true
          git push origin HEAD:main
